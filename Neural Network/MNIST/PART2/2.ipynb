{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 style=\"color:#3295ec;\"><center>بسم الله الرحمن الرحيم</center></h1>\n",
    "\n",
    "<h3 style=\"color:#3295ec;\"><center>تمرین دوم درس شبکه های عصبی مصنوعی - قسمت دوم</center></h3>\n",
    "<p style=\"text-align: right;\">نام و نام خانوادگی :فرامرز نادری</p>\n",
    "<p style=\"text-align: right;\">97722203:شماره دانشجویی</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting data\\train-images-idx3-ubyte.gz\n",
      "Extracting data\\train-labels-idx1-ubyte.gz\n",
      "Extracting data\\t10k-images-idx3-ubyte.gz\n",
      "Extracting data\\t10k-labels-idx1-ubyte.gz\n",
      "Test shape: (10000, 784)\n",
      "Train shape: (60000, 784)\n"
     ]
    }
   ],
   "source": [
    "#data\n",
    "import tensorflow as tf\n",
    "from tensorflow.examples.tutorials.mnist import input_data as mnist_data\n",
    "mnist = mnist_data.read_data_sets(\"data\", one_hot=True, reshape=True, validation_size=0)\n",
    "print('Test shape:',mnist.test.images.shape)\n",
    "print('Train shape:',mnist.train.images.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"text-align: right;\">به نظر شما ابعاد مناسب برای این مجموعه داده چه می باشد؟</p>\n",
    "<p style=\"text-align: right;\"> به نظر من یک شبکه دو بعدی بیشتر از 10 نورون در هر بعد مثلا 15*15 نورون البته باید با داده های آموزشی بیشتر از آنچه من دادم آموزش ببیند و چونکه بهتر از یک بعدی دقت بدست می آید</p>\n",
    "\n",
    "<p style=\"text-align: right;\">برای اندازه گیری دقت چه روشی را پیشنهاد می کنید؟</p>\n",
    "<p style=\"text-align: right;\">درون هر خوشه کلاس های داده هایی را که در آن خوشه افتاده بودند گذاشتم بعد هر کلاسی که بیشترین تعداد را داشت آن خوشه را به اسم آن کلاس گذاشتم و تعداد داده هایی که در آن خوشه لیبل آن کلاس را داشتند به تعداد کل داده های آن خوشه تقسیم کردم و در آخر از دقت خوشه ها میانگین گرفتم </p>\n",
    "\n",
    "<p style=\"text-align: right;\">به هر کلاس چند نورون تخصیص داده شده؟  دقت بدست آمده برای معماری شما و شبکه های زیر چند است؟</p>\n",
    "\n",
    "<p style=\"text-align: right;\">معماری من 15*15 نورون </p>\n",
    "\n",
    "<p style=\"text-align: right;\">شبکه یک بعدی 10 نورون</p>\n",
    "\n",
    "<p style=\"text-align: right;\">شبکه یک بعدی 100 نورون</p>\n",
    "\n",
    "<p style=\"text-align: right;\">شبکه دو بعدی 5*5 نورون</p>\n",
    "\n",
    "<p style=\"text-align: right;\">شبکه دو بعدی 10*10 نورون</p>\n",
    "\n",
    "<img src=\"photo.jpg\" >\n",
    "\n",
    "<p style=\"text-align: right;\"> آیا به هرخوشه تعداد یکسانی نورون تخصیص یافته؟ خیر این توزیع نورون ها بر چه اساسی است؟ بستگی به میزان تراکم داده ها در فضا دارد یعنی هرچه در ناحیه ای تراکم داده ها بیشتر باشد در آن ناحیه نورون بیشتری وجود دارد و شکل ناحیه های پرتراکم را به خود می گیرد</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "def kohonen(N,length,width,dim,r,L):\n",
    "    #Initialization\n",
    "    np.random.seed(0)\n",
    "    w=np.random.rand(784,N)\n",
    "    learning_rate=learning_rate0=L\n",
    "    R=R0=r\n",
    "    if dim==1:\n",
    "        neurons=np.arange(0,N)\n",
    "       # print(neurons)\n",
    "    elif dim==2:\n",
    "        neurons=np.arange(0,N)\n",
    "        neurons=np.reshape(neurons,(width,length))\n",
    "        \n",
    "    for t in range (1,101):\n",
    "        for j in range (0,1000):\n",
    "            #Competition\n",
    "            dist = [np.linalg.norm(w[:,i]-mnist.train.images[j,:]) for i in range (0,N) ]\n",
    "            i=dist.index(np.min(dist))\n",
    "          #  print(i)\n",
    "            if dim==2:\n",
    "                #Cooperation\n",
    "                d=[]\n",
    "                I,J=np.where(neurons==int(i))\n",
    "                for M in range(0,width): \n",
    "                     for K in range(0,length):\n",
    "                            d.append(np.sqrt(np.power(I - M, 2) + np.power(J - K, 2)))\n",
    "                dist=np.reshape(d,(width,length))\n",
    "              # print(dist)\n",
    "                h=np.exp(-1*(dist*dist)/(2*R*R))\n",
    "                h1=np.reshape(h,(1,N))\n",
    "                #Update Weights\n",
    "                l=np.add(w.transpose(),np.transpose(h1*learning_rate)*(np.array(N*[mnist.train.images[j,:]])-w.transpose()))\n",
    "            elif dim==1:\n",
    "                #Cooperation\n",
    "                d=[neurons[int(i)] for j in range(0,N)]\n",
    "                dist = np.subtract(d,neurons)\n",
    "              #  print(dist)\n",
    "                h=np.exp(-1*(dist*dist)/(2*R*R))\n",
    "                #print( h)\n",
    "                #Update Weights\n",
    "                l=np.add(w.transpose(),np.transpose([h*learning_rate])*(np.array(N*[mnist.train.images[j,:]])-w.transpose()))\n",
    "         #   print(l)\n",
    "            w=l.transpose()\n",
    "         #   print(w)\n",
    "        learning_rate=learning_rate0* np.exp(-float(t) / 100)\n",
    "        R=float(R0) * np.exp(-float(t) / 100)\n",
    "    return w\n",
    "\n",
    "def test(w,N,n):\n",
    "    cluster=[[] for i in range(0,N)]\n",
    "    Class=[0 for i in range(0,10)]\n",
    "    for k in range (0,n):\n",
    "        dist = [np.linalg.norm(w[:,i]-mnist.test.images[k,]) for i in range (0,np.size(w,1)) ]\n",
    "        i=dist.index(np.min(dist))\n",
    "\n",
    "        s=mnist.test.labels[k,]\n",
    "        if s[0]==1:\n",
    "            u=0\n",
    "        elif s[1]==1:\n",
    "            u=1\n",
    "        elif s[2]==1:\n",
    "            u=2\n",
    "        elif s[3]==1:\n",
    "            u=3\n",
    "        elif s[4]==1:\n",
    "            u=4\n",
    "        elif s[5]==1:\n",
    "            u=5\n",
    "        elif s[6]==1:\n",
    "            u=6\n",
    "        elif s[7]==1:\n",
    "            u=7\n",
    "        elif s[8]==1:\n",
    "            u=8\n",
    "        elif s[9]==1:\n",
    "            u=9\n",
    "\n",
    "        cluster[i].append(u)\n",
    "\n",
    "    #print(cluster)\n",
    "\n",
    "    accuracy=0\n",
    "    numofcluster=0\n",
    "    for i in range(0,N):\n",
    "        if cluster[i]!=[]:\n",
    "            n=np.argmax(np.bincount(cluster[i]))\n",
    "            n1=cluster[i].count(n)\n",
    "            Class[n]+=1\n",
    "            m=np.sum(np.bincount(cluster[i]))\n",
    "            accuracycluster=n1/m\n",
    "            #print(n,accuracycluster)\n",
    "            accuracy=accuracy+accuracycluster\n",
    "            numofcluster=numofcluster+1\n",
    "    print(accuracy/numofcluster)\n",
    "    print(Class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "117.58470416069031\n",
      "Wall time: 1min 57s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "import time\n",
    "t1 = time.time() \n",
    "w=kohonen(N=100,length=100,width=1,dim=1,r=3,L=0.1)\n",
    "print(time.time()-t1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7609831291352205\n",
      "[10, 11, 10, 9, 11, 8, 10, 13, 8, 10]\n"
     ]
    }
   ],
   "source": [
    "test(w,N=100,n=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
